# services/native_script_service.py
import logging
from typing import Dict, Tuple, Optional

logger = logging.getLogger(__name__)


class NativeScriptService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —É–ª—É—á—à–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –Ω–∞—Ç–∏–≤–Ω—ã—Ö –ø–∏—Å—å–º–µ–Ω–Ω–æ—Å—Ç—è—Ö
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–∑–∏–∞—Ç—Å–∫–∏–µ —è–∑—ã–∫–∏: –∫—Ö–º–µ—Ä—Å–∫–∏–π, —Ç–∞–π—Å–∫–∏–π, –∫–∏—Ç–∞–π—Å–∫–∏–π, —è–ø–æ–Ω—Å–∫–∏–π, –∫–æ—Ä–µ–π—Å–∫–∏–π, –≤—å–µ—Ç–Ω–∞–º—Å–∫–∏–π
    """

    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Unicode –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–∏—Å—å–º–µ–Ω–Ω–æ—Å—Ç–µ–π
        self.script_ranges = {
            'khmer': (0x1780, 0x17FF),  # –ö—Ö–º–µ—Ä—Å–∫–∏–π
            'thai': (0x0E00, 0x0E7F),  # –¢–∞–π—Å–∫–∏–π
            'chinese': (0x4E00, 0x9FFF),  # CJK Unified Ideographs
            'hiragana': (0x3040, 0x309F),  # –Ø–ø–æ–Ω—Å–∫–∞—è —Ö–∏—Ä–∞–≥–∞–Ω–∞
            'katakana': (0x30A0, 0x30FF),  # –Ø–ø–æ–Ω—Å–∫–∞—è –∫–∞—Ç–∞–∫–∞–Ω–∞
            'hangul': (0xAC00, 0xD7AF),  # –ö–æ—Ä–µ–π—Å–∫–∏–π —Ö–∞–Ω–≥—ã–ª—å
            'hangul_jamo': (0x1100, 0x11FF),  # –ö–æ—Ä–µ–π—Å–∫–∏–µ jamo
            'vietnamese': (0x1EA0, 0x1EF9),  # –í—å–µ—Ç–Ω–∞–º—Å–∫–∏–µ –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–∏
        }

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–æ–≤ –≤ –ª–∞—Ç–∏–Ω–∏—Ü–µ
        self.transliteration_keywords = {
            'km': [
                'bong', 'avan', 'kue', 'vie', 'mien', 'dak', 'chun', 'neng',
                'phnom penh', 'kath', 'chui', 'tae', 'doi', 'knea', 'tam',
                'thap', 'reang', 'sva', 'kam', 'krong', 'tlai', 'vreak',
                'sosay', 'masin', 'rodh', 'pran', 'mak', 'nesol', 'cambodia'
            ],
            'th': [
                'thai', 'thailand', 'bangkok', 'krung', 'thep', 'mai', 'chai',
                'sabai', 'aroi', 'khrap', 'kha', 'sanuk', 'nam', 'khao'
            ],
            'vi': [
                'vietnam', 'viet', 'saigon', 'hanoi', 'pho', 'banh', 'com',
                'nuoc', 'chao', 'xin', 'cam', 'gia', 'nha', 'toi'
            ],
            'zh': [
                'china', 'chinese', 'beijing', 'shanghai', 'ni hao', 'xie xie',
                'zai jian', 'wo shi', 'zhong guo', 'hen hao'
            ],
            'ja': [
                'japan', 'japanese', 'tokyo', 'osaka', 'arigatou', 'konnichiwa',
                'sayonara', 'watashi', 'anata', 'desu', 'masu'
            ],
            'ko': [
                'korea', 'korean', 'seoul', 'annyeong', 'saranghae', 'gamsahamnida',
                'yeoboseyo', 'naneun', 'dangsin', 'hankook'
            ]
        }

    def analyze_script_quality(self, text: str, expected_language: str) -> Dict[str, any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞—Ç–∏–≤–Ω–æ–π –ø–∏—Å—å–º–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–µ

        Args:
            text: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π —Ç–µ–∫—Å—Ç
            expected_language: –û–∂–∏–¥–∞–µ–º—ã–π —è–∑—ã–∫ (km, th, zh, ja, ko, vi)

        Returns:
            dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        if not text:
            return {'native_ratio': 0, 'quality': 'empty', 'has_transliteration': False}

        analysis = {
            'native_ratio': 0,
            'quality': 'poor',
            'has_transliteration': False,
            'script_counts': {},
            'total_chars': 0,
            'recommendations': []
        }

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∏–º–≤–æ–ª—ã —Ä–∞–∑–Ω—ã—Ö –ø–∏—Å—å–º–µ–Ω–Ω–æ—Å—Ç–µ–π
        analysis['script_counts'] = self._count_script_characters(text)
        analysis['total_chars'] = sum(analysis['script_counts'].values())

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —è–∑—ã–∫–∞
        if expected_language == 'km':
            analysis.update(self._analyze_khmer_quality(text, analysis['script_counts']))
        elif expected_language == 'th':
            analysis.update(self._analyze_thai_quality(text, analysis['script_counts']))
        elif expected_language == 'zh':
            analysis.update(self._analyze_chinese_quality(text, analysis['script_counts']))
        elif expected_language == 'ja':
            analysis.update(self._analyze_japanese_quality(text, analysis['script_counts']))
        elif expected_language == 'ko':
            analysis.update(self._analyze_korean_quality(text, analysis['script_counts']))
        elif expected_language == 'vi':
            analysis.update(self._analyze_vietnamese_quality(text, analysis['script_counts']))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏
        analysis['has_transliteration'] = self._has_transliteration(text, expected_language)

        return analysis

    def _count_script_characters(self, text: str) -> Dict[str, int]:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å–∏–º–≤–æ–ª—ã —Ä–∞–∑–Ω—ã—Ö –ø–∏—Å—å–º–µ–Ω–Ω–æ—Å—Ç–µ–π"""
        counts = {script: 0 for script in self.script_ranges.keys()}
        counts['latin'] = 0
        counts['other'] = 0

        for char in text:
            if char.isalpha():
                categorized = False
                for script, (start, end) in self.script_ranges.items():
                    if start <= ord(char) <= end:
                        counts[script] += 1
                        categorized = True
                        break

                if not categorized:
                    if 'a' <= char.lower() <= 'z':
                        counts['latin'] += 1
                    else:
                        counts['other'] += 1

        return counts

    def _analyze_khmer_quality(self, text: str, script_counts: Dict) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫—Ö–º–µ—Ä—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        total_alpha = sum(script_counts.values())
        khmer_count = script_counts.get('khmer', 0)

        if total_alpha == 0:
            return {'native_ratio': 0, 'quality': 'empty'}

        khmer_ratio = khmer_count / total_alpha

        quality_info = {
            'native_ratio': khmer_ratio,
            'khmer_chars': khmer_count,
            'latin_chars': script_counts.get('latin', 0),
        }

        if khmer_ratio >= 0.8:
            quality_info.update({
                'quality': 'excellent',
                'message': "‚úÖ ·ûÄ·ûò·üí·ûò·ûú·û∑·ûí·û∏·ûî·û∂·ûì·ûä·ûÄ·ûü·üí·ûö·ûÑ·üã·û¢·ûÄ·üí·ûü·ûö·ûÅ·üí·ûò·üÇ·ûö·ûä·üÑ·ûô·ûá·üÑ·ûÇ·ûá·üê·ûô"
            })
        elif khmer_ratio >= 0.5:
            quality_info.update({
                'quality': 'good',
                'message': "‚úì ·ûÄ·û∂·ûö·ûä·ûÄ·ûü·üí·ûö·ûÑ·üã·û¢·ûÄ·üí·ûü·ûö·ûÅ·üí·ûò·üÇ·ûö·ûõ·üí·û¢"
            })
        elif khmer_ratio >= 0.2:
            quality_info.update({
                'quality': 'mixed',
                'message': "‚ö†Ô∏è ·ûÄ·û∂·ûö·ûä·ûÄ·ûü·üí·ûö·ûÑ·üã·ûÖ·ûò·üí·ûö·ûª·üá (·ûò·û∂·ûì·û¢·ûÄ·üí·ûü·ûö·ûÅ·üí·ûò·üÇ·ûö·ûÅ·üí·ûõ·üá)",
                'recommendations': [
                    "·ûì·û∑·ûô·û∂·ûô·ûô·û∫·ûè·üó ·ûì·û∑·ûÑ·ûÖ·üí·ûî·û∂·ûü·üã",
                    "·ûÄ·ûª·üÜ·ûõ·û∂·ûô·ûó·û∂·ûü·û∂·û¢·ûÑ·üã·ûÇ·üí·ûõ·üÅ·ûü",
                    "·ûê·ûè·ûÄ·üí·ûì·ûª·ûÑ·ûÄ·ûì·üí·ûõ·üÇ·ûÑ·ûü·üí·ûÑ·û∂·ûè·üã"
                ]
            })
        else:
            quality_info.update({
                'quality': 'poor',
                'message': "‚ùå ·ûÄ·û∂·ûö·ûä·ûÄ·ûü·üí·ûö·ûÑ·üã·ûò·û∑·ûì·ûî·û∂·ûì·ûÇ·ûª·ûé·ûó·û∂·ûñ·ûõ·üí·û¢",
                'recommendations': [
                    "·ûì·û∑·ûô·û∂·ûô·ûÅ·üí·ûò·üÇ·ûö·ûü·ûª·ûë·üí·ûí",
                    "·ûì·û∑·ûô·û∂·ûô·ûô·û∫·ûè·üó ·ûì·û∑·ûÑ·ûÖ·üí·ûî·û∂·ûü·üã",
                    "·ûê·ûè·ûÄ·üí·ûì·ûª·ûÑ·ûÄ·ûì·üí·ûõ·üÇ·ûÑ·ûü·üí·ûÑ·û∂·ûè·üã",
                    "·ûî·üí·ûö·ûæ·ûò·üâ·û∂·ûô·ûÄ·üí·ûö·ûº·û†·üí·ûú·ûº·ûì·ûõ·üí·û¢"
                ]
            })

        return quality_info

    def _analyze_thai_quality(self, text: str, script_counts: Dict) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–∞–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        total_alpha = sum(script_counts.values())
        thai_count = script_counts.get('thai', 0)

        if total_alpha == 0:
            return {'native_ratio': 0, 'quality': 'empty'}

        thai_ratio = thai_count / total_alpha

        quality_info = {'native_ratio': thai_ratio}

        if thai_ratio >= 0.8:
            quality_info.update({
                'quality': 'excellent',
                'message': "‚úÖ ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à"
            })
        elif thai_ratio >= 0.5:
            quality_info.update({
                'quality': 'good',
                'message': "‚úì ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÑ‡∏î‡πâ‡∏î‡∏µ"
            })
        elif thai_ratio >= 0.2:
            quality_info.update({
                'quality': 'mixed',
                'message': "‚ö†Ô∏è ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏ö‡∏ö‡∏ú‡∏™‡∏° (‡∏°‡∏µ‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÑ‡∏ó‡∏¢‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô)",
                'recommendations': [
                    "‡∏û‡∏π‡∏î‡∏ä‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô",
                    "‡∏≠‡∏¢‡πà‡∏≤‡∏ú‡∏™‡∏°‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©",
                    "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏á‡∏µ‡∏¢‡∏ö"
                ]
            })
        else:
            quality_info.update({
                'quality': 'poor',
                'message': "‚ùå ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡∏î‡∏µ",
                'recommendations': [
                    "‡∏û‡∏π‡∏î‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏•‡πâ‡∏ß‡∏ô‡πÜ",
                    "‡∏û‡∏π‡∏î‡∏ä‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô",
                    "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏á‡∏µ‡∏¢‡∏ö",
                    "‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡∏Ñ‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ"
                ]
            })

        return quality_info

    def _analyze_chinese_quality(self, text: str, script_counts: Dict) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–∏—Ç–∞–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        total_alpha = sum(script_counts.values())
        chinese_count = script_counts.get('chinese', 0)

        if total_alpha == 0:
            return {'native_ratio': 0, 'quality': 'empty'}

        chinese_ratio = chinese_count / total_alpha

        quality_info = {'native_ratio': chinese_ratio}

        if chinese_ratio >= 0.8:
            quality_info.update({
                'quality': 'excellent',
                'message': "‚úÖ ‰∏≠ÊñáËØ≠Èü≥ËΩ¨ÊñáÂ≠óÊàêÂäü"
            })
        elif chinese_ratio >= 0.5:
            quality_info.update({
                'quality': 'good',
                'message': "‚úì ‰∏≠ÊñáËΩ¨Êç¢ÊïàÊûúËâØÂ•Ω"
            })
        elif chinese_ratio >= 0.2:
            quality_info.update({
                'quality': 'mixed',
                'message': "‚ö†Ô∏è Ê∑∑ÂêàËØ≠Ë®ÄËΩ¨ÂΩï (ÈÉ®ÂàÜ‰∏≠Êñá)",
                'recommendations': [
                    "ËØ¥ËØùÊÖ¢‰∏Ä‰∫õÔºåÊ∏ÖÊ•ö‰∏Ä‰∫õ",
                    "‰∏çË¶ÅÊ∑∑ÂêàËã±ËØ≠",
                    "Âú®ÂÆâÈùôÁöÑÂú∞ÊñπÂΩïÈü≥"
                ]
            })
        else:
            quality_info.update({
                'quality': 'poor',
                'message': "‚ùå ËΩ¨ÂΩïË¥®Èáè‰∏ç‰Ω≥",
                'recommendations': [
                    "ËØ¥Á∫Ø‰∏≠Êñá",
                    "ËØ¥ËØùÊÖ¢‰∏Ä‰∫õÔºåÊ∏ÖÊ•ö‰∏Ä‰∫õ",
                    "Âú®ÂÆâÈùôÁöÑÂú∞ÊñπÂΩïÈü≥",
                    "‰ΩøÁî®Â•ΩÁöÑÈ∫¶ÂÖãÈ£é"
                ]
            })

        return quality_info

    def _analyze_japanese_quality(self, text: str, script_counts: Dict) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —è–ø–æ–Ω—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        total_alpha = sum(script_counts.values())
        hiragana = script_counts.get('hiragana', 0)
        katakana = script_counts.get('katakana', 0)
        kanji = script_counts.get('chinese', 0)  # Kanji –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–∏—Ç–∞–π—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
        japanese_total = hiragana + katakana + kanji

        if total_alpha == 0:
            return {'native_ratio': 0, 'quality': 'empty'}

        japanese_ratio = japanese_total / total_alpha

        quality_info = {
            'native_ratio': japanese_ratio,
            'hiragana_count': hiragana,
            'katakana_count': katakana,
            'kanji_count': kanji
        }

        if japanese_ratio >= 0.8:
            quality_info.update({
                'quality': 'excellent',
                'message': "‚úÖ Êó•Êú¨Ë™ûÈü≥Â£∞Ë™çË≠ò„ÅåÊàêÂäü„Åó„Åæ„Åó„Åü"
            })
        elif japanese_ratio >= 0.5:
            quality_info.update({
                'quality': 'good',
                'message': "‚úì Êó•Êú¨Ë™û„ÅÆË™çË≠ò„ÅåËâØÂ•Ω„Åß„Åô"
            })
        elif japanese_ratio >= 0.2:
            quality_info.update({
                'quality': 'mixed',
                'message': "‚ö†Ô∏è Ê∑∑ÂêàË®ÄË™û„ÅÆË™çË≠ò (‰∏ÄÈÉ®Êó•Êú¨Ë™û)",
                'recommendations': [
                    "„ÇÜ„Å£„Åè„Çä„ÅØ„Å£„Åç„Çä„Å®Ë©±„Åô",
                    "Ëã±Ë™û„ÇíÊ∑∑„Åú„Å™„ÅÑ",
                    "Èùô„Åã„Å™Â†¥ÊâÄ„ÅßÈå≤Èü≥„Åô„Çã"
                ]
            })
        else:
            quality_info.update({
                'quality': 'poor',
                'message': "‚ùå Ë™çË≠òÂìÅË≥™„ÅåËâØ„Åè„ÅÇ„Çä„Åæ„Åõ„Çì",
                'recommendations': [
                    "Á¥îÁ≤ã„Å™Êó•Êú¨Ë™û„ÇíË©±„Åô",
                    "„ÇÜ„Å£„Åè„Çä„ÅØ„Å£„Åç„Çä„Å®Ë©±„Åô",
                    "Èùô„Åã„Å™Â†¥ÊâÄ„ÅßÈå≤Èü≥„Åô„Çã",
                    "ËâØ„ÅÑ„Éû„Ç§„ÇØ„Çí‰ΩøÁî®„Åô„Çã"
                ]
            })

        return quality_info

    def _analyze_korean_quality(self, text: str, script_counts: Dict) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ—Ä–µ–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        total_alpha = sum(script_counts.values())
        hangul = script_counts.get('hangul', 0) + script_counts.get('hangul_jamo', 0)

        if total_alpha == 0:
            return {'native_ratio': 0, 'quality': 'empty'}

        korean_ratio = hangul / total_alpha

        quality_info = {'native_ratio': korean_ratio}

        if korean_ratio >= 0.8:
            quality_info.update({
                'quality': 'excellent',
                'message': "‚úÖ ÌïúÍµ≠Ïñ¥ ÏùåÏÑ± Ïù∏ÏãùÏù¥ ÏÑ±Í≥µÌñàÏäµÎãàÎã§"
            })
        elif korean_ratio >= 0.5:
            quality_info.update({
                'quality': 'good',
                'message': "‚úì ÌïúÍµ≠Ïñ¥ Ïù∏ÏãùÏù¥ ÏñëÌò∏Ìï©ÎãàÎã§"
            })
        elif korean_ratio >= 0.2:
            quality_info.update({
                'quality': 'mixed',
                'message': "‚ö†Ô∏è ÌòºÌï© Ïñ∏Ïñ¥ Ïù∏Ïãù (ÏùºÎ∂Ä ÌïúÍµ≠Ïñ¥)",
                'recommendations': [
                    "Ï≤úÏ≤úÌûà Î™ÖÌôïÌïòÍ≤å ÎßêÌïòÍ∏∞",
                    "ÏòÅÏñ¥Î•º ÏÑûÏßÄ ÏïäÍ∏∞",
                    "Ï°∞Ïö©Ìïú Í≥≥ÏóêÏÑú ÎÖπÏùåÌïòÍ∏∞"
                ]
            })
        else:
            quality_info.update({
                'quality': 'poor',
                'message': "‚ùå Ïù∏Ïãù ÌíàÏßàÏù¥ Ï¢ãÏßÄ ÏïäÏäµÎãàÎã§",
                'recommendations': [
                    "ÏàúÏàòÌïú ÌïúÍµ≠Ïñ¥Î°ú ÎßêÌïòÍ∏∞",
                    "Ï≤úÏ≤úÌûà Î™ÖÌôïÌïòÍ≤å ÎßêÌïòÍ∏∞",
                    "Ï°∞Ïö©Ìïú Í≥≥ÏóêÏÑú ÎÖπÏùåÌïòÍ∏∞",
                    "Ï¢ãÏùÄ ÎßàÏù¥ÌÅ¨ ÏÇ¨Ïö©ÌïòÍ∏∞"
                ]
            })

        return quality_info

    def _analyze_vietnamese_quality(self, text: str, script_counts: Dict) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –≤—å–µ—Ç–Ω–∞–º—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        # –í—å–µ—Ç–Ω–∞–º—Å–∫–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–∞—Ç–∏–Ω–∏—Ü—É —Å –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–∞–º–∏
        total_alpha = sum(script_counts.values())
        vietnamese_markers = script_counts.get('vietnamese', 0)
        latin_count = script_counts.get('latin', 0)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—å–µ—Ç–Ω–∞–º—Å–∫–∏—Ö –¥–∏–∞–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–Ω–∞–∫–æ–≤
        vietnamese_diacritics = sum(1 for char in text if '\u1EA0' <= char <= '\u1EF9')
        vietnamese_ratio = vietnamese_diacritics / len(text) if text else 0

        quality_info = {'native_ratio': vietnamese_ratio}

        if vietnamese_ratio >= 0.1:  # –î–ª—è –≤—å–µ—Ç–Ω–∞–º—Å–∫–æ–≥–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ 10% –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–æ–≤
            quality_info.update({
                'quality': 'excellent',
                'message': "‚úÖ Nh·∫≠n d·∫°ng ti·∫øng Vi·ªát th√†nh c√¥ng"
            })
        elif latin_count > 0 and self._has_vietnamese_words(text):
            quality_info.update({
                'quality': 'good',
                'message': "‚úì Nh·∫≠n d·∫°ng ti·∫øng Vi·ªát t·ªët"
            })
        else:
            quality_info.update({
                'quality': 'poor',
                'message': "‚ùå Ch·∫•t l∆∞·ª£ng nh·∫≠n d·∫°ng kh√¥ng t·ªët",
                'recommendations': [
                    "N√≥i ti·∫øng Vi·ªát thu·∫ßn t√∫y",
                    "N√≥i ch·∫≠m v√† r√µ r√†ng",
                    "Ghi √¢m ·ªü n∆°i y√™n tƒ©nh"
                ]
            })

        return quality_info

    def _has_transliteration(self, text: str, language: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞"""
        if language not in self.transliteration_keywords:
            return False

        text_lower = text.lower()
        keywords = self.transliteration_keywords[language]

        found_keywords = sum(1 for keyword in keywords if keyword in text_lower)
        return found_keywords >= 2  # –ú–∏–Ω–∏–º—É–º 2 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è

    def _has_vietnamese_words(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≤—å–µ—Ç–Ω–∞–º—Å–∫–∏—Ö —Å–ª–æ–≤"""
        vietnamese_words = ['vietnam', 'viet', 'pho', 'banh', 'xin', 'chao', 'cam on']
        text_lower = text.lower()
        return any(word in text_lower for word in vietnamese_words)

    def format_quality_message(self, analysis: Dict, language: str) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –∫–∞—á–µ—Å—Ç–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏

        Args:
            analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç analyze_script_quality
            language: –ö–æ–¥ —è–∑—ã–∫–∞

        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        """
        message = analysis.get('message', '')

        if analysis.get('recommendations'):
            message += "\n\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n"
            for rec in analysis['recommendations']:
                message += f"‚Ä¢ {rec}\n"

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –µ—Å–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–µ –æ—Ç–ª–∏—á–Ω–æ–µ
        if analysis.get('quality') != 'excellent' and analysis.get('native_ratio', 0) > 0:
            message += f"\nüìä –ù–∞—Ç–∏–≤–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: {analysis['native_ratio']:.1%}"

        return message.strip()

    def should_retry_transcription(self, analysis: Dict) -> bool:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —Å—Ç–æ–∏—Ç –ª–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º —è–∑—ã–∫–æ–º

        Args:
            analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            True –µ—Å–ª–∏ —Å—Ç–æ–∏—Ç –ø–æ–≤—Ç–æ—Ä–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
        """
        return (analysis.get('has_transliteration', False) and
                analysis.get('native_ratio', 0) < 0.3)
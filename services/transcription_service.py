import os
import logging
import openai
from .audio_processor import AudioProcessor
from .language_detector import LanguageDetector

logger = logging.getLogger(__name__)


class TranscriptionService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ"""

    def __init__(self):
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.audio_processor = AudioProcessor()
        self.language_detector = LanguageDetector()

        if not self.openai_api_key:
            logger.warning("OPENAI_API_KEY not found")
            self.client_ready = False
        else:
            try:
                openai.api_key = self.openai_api_key
                self.client_ready = True
                logger.info("OpenAI Transcription API initialized")
            except Exception as e:
                logger.error(f"Failed to initialize OpenAI: {e}")
                self.client_ready = False

    def transcribe_from_url(self, media_url, media_type='audio', user_subscription='free'):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –º–µ–¥–∏–∞ –ø–æ URL"""
        if not self.client_ready:
            return self._mock_result()

        temp_file_path = None
        try:
            # 1. –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
            media_data = self.audio_processor.download_media(media_url)

            # 2. –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ñ–∞–π–ª
            estimated_duration = self.audio_processor.validate_media_file(
                media_data, media_type, user_subscription
            )

            # 3. –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_file_path = self.audio_processor.create_temp_file(media_data, media_type)

            # 4. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
            result = self._transcribe_file(temp_file_path)

            # 5. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if result['success']:
                # –£–ª—É—á—à–∞–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
                language_analysis = self.language_detector.analyze_text_language(
                    result['text'], result.get('language_code')
                )

                result.update({
                    'language': self.language_detector.get_language_name(language_analysis['final_language']),
                    'language_code': language_analysis['final_language'],
                    'language_confidence': language_analysis['confidence'],
                    'duration': estimated_duration,
                    'media_type': media_type
                })

            return result

        except ValueError as e:
            return {'success': False, 'error': str(e)}
        except Exception as e:
            logger.error(f"Transcription error: {e}")
            return {'success': False, 'error': '–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'}
        finally:
            if temp_file_path:
                self.audio_processor.cleanup_temp_file(temp_file_path)

    def transcribe_from_data(self, media_data, media_type='audio', user_subscription='free'):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –º–µ–¥–∏–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –≤ –ø–∞–º—è—Ç–∏"""
        if not self.client_ready:
            return self._mock_result()

        temp_file_path = None
        try:
            # 1. –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ñ–∞–π–ª
            estimated_duration = self.audio_processor.validate_media_file(
                media_data, media_type, user_subscription
            )

            # 2. –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_file_path = self.audio_processor.create_temp_file(media_data, media_type)

            # 3. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
            result = self._transcribe_file(temp_file_path)

            # 4. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if result['success']:
                language_analysis = self.language_detector.analyze_text_language(
                    result['text'], result.get('language_code')
                )

                result.update({
                    'language': self.language_detector.get_language_name(language_analysis['final_language']),
                    'language_code': language_analysis['final_language'],
                    'language_confidence': language_analysis['confidence'],
                    'duration': estimated_duration,
                    'media_type': media_type
                })

            return result

        except ValueError as e:
            return {'success': False, 'error': str(e)}
        except Exception as e:
            logger.error(f"Transcription error: {e}")
            return {'success': False, 'error': '–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'}
        finally:
            if temp_file_path:
                self.audio_processor.cleanup_temp_file(temp_file_path)

    def _transcribe_file(self, file_path):
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Ñ–∞–π–ª–∞"""
        try:
            logger.info("Starting OpenAI transcription")

            with open(file_path, 'rb') as audio_file:
                transcript = openai.Audio.transcribe(
                    model="whisper-1",
                    file=audio_file,
                    response_format="json"
                )

            text = transcript['text'].strip()
            language_code = transcript.get('language', 'unknown')

            logger.info(f"Transcription completed. Detected language: {language_code}")

            return {
                'success': True,
                'text': text,
                'language_code': language_code,
                'raw_response': transcript
            }

        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            return self._handle_api_error(e)

    def _handle_api_error(self, error):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ OpenAI API"""
        error_message = str(error)

        if "insufficient_quota" in error_message:
            return {
                'success': False,
                'error': '–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ OpenAI API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
            }
        elif "invalid_request_error" in error_message:
            return {
                'success': False,
                'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞.'
            }
        elif "rate_limit" in error_message:
            return {
                'success': False,
                'error': '–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É.'
            }
        else:
            return {
                'success': False,
                'error': '–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
            }

    def _mock_result(self):
        """–ó–∞–≥–ª—É—à–∫–∞ –∫–æ–≥–¥–∞ API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        return {
            'success': True,
            'text': 'üîß –ù–∞—Å—Ç—Ä–æ–π—Ç–µ OPENAI_API_KEY –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.',
            'language': 'System Message',
            'language_code': 'sys',
            'duration': 0,
            'media_type': 'audio'
        }

    def get_api_status(self):
        """–°—Ç–∞—Ç—É—Å API"""
        return {
            'transcription_available': self.client_ready,
            'supported_formats': self.audio_processor.supported_formats
        }
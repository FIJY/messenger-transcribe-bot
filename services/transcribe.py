import os
import tempfile
import logging
import io
import openai
from config.constants import MAX_AUDIO_DURATION_FREE, MAX_AUDIO_DURATION_PREMIUM, MAX_FILE_SIZE

logger = logging.getLogger(__name__)


class TranscribeService:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å OpenAI API"""
        self.openai_api_key = os.getenv('OPENAI_API_KEY')

        if not self.openai_api_key:
            logger.warning("OPENAI_API_KEY not found, using mock transcription")
            self.client_ready = False
        else:
            try:
                openai.api_key = self.openai_api_key
                self.client_ready = True
                logger.info("OpenAI Whisper API initialized successfully")
            except Exception as e:
                logger.error(f"Failed to initialize OpenAI client: {e}")
                self.client_ready = False

        # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏
        self.supported_languages = {
            'km': '·ûÅ·üí·ûò·üÇ·ûö',
            'en': 'English',
            'ru': '–†—É—Å—Å–∫–∏–π',
            'zh': '‰∏≠Êñá',
            'th': '‡πÑ‡∏ó‡∏¢',
            'vi': 'Ti·∫øng Vi·ªát',
            'fr': 'Fran√ßais',
            'es': 'Espa√±ol',
            'ja': 'Êó•Êú¨Ë™û',
            'ko': 'ÌïúÍµ≠Ïñ¥',
            'de': 'Deutsch',
            'it': 'Italiano',
            'pt': 'Portugu√™s',
            'ar': 'ÿßŸÑÿπÿ±ÿ®Ÿäÿ©',
            'hi': '‡§π‡§ø‡§®‡•ç‡§¶‡•Ä',
            'tr': 'T√ºrk√ße',
            'pl': 'Polski',
            'nl': 'Nederlands',
            'sv': 'Svenska',
            'da': 'Dansk',
            'no': 'Norsk',
            'fi': 'Suomi'
        }

    def transcribe(self, media_data, user_subscription='free', media_type='audio'):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ OpenAI API"""
        if not self.client_ready:
            return self._mock_transcription()

        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
            if len(media_data) > MAX_FILE_SIZE:
                return {
                    'success': False,
                    'error': f'–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º—É–º {MAX_FILE_SIZE // (1024 * 1024)}MB.'
                }

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
            if media_type == 'video':
                file_suffix = '.mp4'
            else:
                file_suffix = '.mp3'

            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(suffix=file_suffix, delete=False) as tmp_file:
                tmp_file.write(media_data)
                tmp_file_path = tmp_file.name

            logger.info(f"Starting transcription of {media_type} with OpenAI API")

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é (OpenAI API —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ —Å –≤–∏–¥–µ–æ!)
            with open(tmp_file_path, 'rb') as media_file:
                transcript = openai.Audio.transcribe(
                    model="whisper-1",
                    file=media_file,
                    response_format="json"
                )

            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.unlink(tmp_file_path)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫
            detected_language = transcript.get('language', 'unknown')
            language_name = self.supported_languages.get(
                detected_language,
                detected_language.upper() if detected_language else 'Auto-detected'
            )

            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç
            text = transcript['text'].strip()

            # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–∞
            estimated_duration = self._estimate_duration(len(media_data))
            max_duration = MAX_AUDIO_DURATION_PREMIUM if user_subscription == 'premium' else MAX_AUDIO_DURATION_FREE

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
            if estimated_duration > max_duration:
                duration_minutes = max_duration // 60
                return {
                    'success': False,
                    'error': f'–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π. –ú–∞–∫—Å–∏–º—É–º {duration_minutes} –º–∏–Ω—É—Ç –¥–ª—è –≤–∞—à–µ–≥–æ —Ç–∞—Ä–∏—Ñ–∞.'
                }

            logger.info(f"Transcription completed successfully. Language: {detected_language}")

            return {
                'success': True,
                'text': text,
                'language': language_name,
                'language_code': detected_language,
                'duration': estimated_duration,
                'media_type': media_type
            }

        except Exception as e:
            logger.error(f"OpenAI transcription error: {e}")

            try:
                if 'tmp_file_path' in locals():
                    os.unlink(tmp_file_path)
            except:
                pass

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
            error_message = str(e)
            if "insufficient_quota" in error_message:
                return {
                    'success': False,
                    'error': '–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ OpenAI API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
                }
            elif "audio" in error_message.lower() or "video" in error_message.lower():
                return {
                    'success': False,
                    'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–µ–¥–∏–∞ —Ñ–∞–π–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–∏.'
                }
            else:
                return {
                    'success': False,
                    'error': '–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
                }

    def _estimate_duration(self, file_size_bytes):
        """–ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–∞"""
        # –û—á–µ–Ω—å –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞: 1MB ‚âà 1 –º–∏–Ω—É—Ç–∞ –¥–ª—è —Å–∂–∞—Ç–æ–≥–æ –∞—É–¥–∏–æ
        # –î–ª—è –≤–∏–¥–µ–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –±–æ–ª—å—à–µ
        estimated_minutes = file_size_bytes / (1024 * 1024)  # MB
        return int(estimated_minutes * 60)  # —Å–µ–∫—É–Ω–¥—ã

    def translate_to_english(self, media_data, media_type='audio'):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∏ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –≤ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π"""
        if not self.client_ready:
            return {
                'success': True,
                'text': 'üîß Translation service will be available after API setup.',
                'original_language': 'unknown'
            }

        try:
            file_suffix = '.mp4' if media_type == 'video' else '.mp3'

            with tempfile.NamedTemporaryFile(suffix=file_suffix, delete=False) as tmp_file:
                tmp_file.write(media_data)
                tmp_file_path = tmp_file.name

            logger.info(f"Starting translation of {media_type} with OpenAI API")

            with open(tmp_file_path, 'rb') as media_file:
                translation = openai.Audio.translate(
                    model="whisper-1",
                    file=media_file,
                    response_format="json"
                )

            os.unlink(tmp_file_path)

            return {
                'success': True,
                'text': translation['text'].strip(),
                'original_language': translation.get('language', 'unknown'),
                'media_type': media_type
            }

        except Exception as e:
            logger.error(f"OpenAI translation error: {e}")
            return self._handle_transcription_error(e)

    def _handle_transcription_error(self, error):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
        error_message = str(error)
        if "insufficient_quota" in error_message:
            return {
                'success': False,
                'error': '–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ OpenAI API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
            }
        elif "audio" in error_message.lower() or "video" in error_message.lower():
            return {
                'success': False,
                'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–µ–¥–∏–∞ —Ñ–∞–π–ª. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–∏.'
            }
        else:
            return {
                'success': False,
                'error': '–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
            }

    def _mock_transcription(self):
        """–í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞ –∫–æ–≥–¥–∞ API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        return {
            'success': True,
            'text': 'üîß –ù–∞—Å—Ç—Ä–æ–π—Ç–µ OPENAI_API_KEY –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.',
            'language': 'System Message',
            'language_code': 'sys',
            'duration': 0,
            'media_type': 'audio'
        }

    def get_supported_languages(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —è–∑—ã–∫–æ–≤"""
        return self.supported_languages

    def is_language_supported(self, language_code):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –ª–∏ —è–∑—ã–∫"""
        return language_code in self.supported_languages